
mm_logit = function(X, y, beta0 = c(0,0), tol = 1e-6, max_iter = 200) {
  
  beta_cur = beta0
  beta_history = gradient_vec = matrix(NA, nrow = max_iter, 
                                       ncol = length(beta0))
  inner_iter <- 0
  for (iter in 1:max_iter) {
    
    # store results
    beta_history[iter,] = beta_cur
    eta <- X %*% beta_cur
    mu <- exp(eta) / (1 + exp(eta))
    
    # set a value for beta_0 because X_i1 = 1 all the time
    beta_0 = log(sum(y)/sum((exp(eta)* exp(-2 *beta_cur[1]))/(1 + exp(eta))))/2
    
    # Newton method to calculate beta_1
    inner_diff <- Inf
    beta_1 = beta_cur[2]
    
    while (inner_diff > tol) {
      exp_term = exp(-2 * X[, 2] * beta_cur[2])
      denom = sum((mu * X[, 2] * exp_term) * exp(2 * X[, 2] * beta_1))
      num = sum(y * X[, 2])
      
      # Compute gradient and Hessian for Newton's update
      f_beta_1 = -denom + num
      f_prime_beta_1 = -2 * sum((mu * X[, 2]^2 * exp_term) * exp(2 * X[, 2] * beta_1))
      
      # Newton update
      beta_1_new = beta_1 - f_beta_1 / f_prime_beta_1
      
      inner_diff = abs(beta_1_new - beta_1)
      beta_1 = beta_1_new
      inner_iter = inner_iter + 1
    }
    
    # Check stopping criterion
    if(sqrt(sum((c(beta_0,beta_1)-beta_cur)^2)) < tol){
      message("Converged in", iter, "iterations.\n")
      break
    }
    
    # Update the solution
    beta_cur = c(beta_0,beta_1)
  }
  
  
  # Compute Fisher information matrix
  eta <- X %*% beta_cur
  mu <- exp(eta) / (1 + exp(eta))
  W <- diag(as.vector(mu * (1 - mu)), nrow = length(y))
  fisher_info <- t(X) %*% W %*% X
  var_cov_matrix <- solve(fisher_info)
  
  return(list(solution = beta_cur, 
              beta_history = beta_history,
              converged = (iter < max_iter),
              niter = iter,
              inner_iter = inner_iter,
              var = var_cov_matrix))
  
}







mm_algorithm <- function(X, Y, tol = 1e-6, max_iter = 100) {
  n <- length(Y)  # number of observations
  X_mat <- cbind(1, X)
  p <- ncol(X_mat)    # number of predictors (including intercept)
  
  beta <- c(0, 0)
  iter <- 0 
  start_time <- Sys.time()  # start timing
  
  while (iter < max_iter) {
    eta <- X_mat %*% beta 
    p_i <- 1 / (1 + exp(-eta))
    
    # Compute weight term based on minorization function
    weight <- exp(eta) / (1 + exp(eta))
    
    # Update each beta_j using the formula in 1.2(C)
    beta_new <- beta
    for (j in 1:p) {
      numerator <- sum(Y * X_mat[, j])
      denominator <- sum(weight * X_mat[, j] * exp(-p * X_mat[, j] * beta[j])) * exp(p * X_mat[, j] * beta[j])
      beta_new[j] <- log(numerator / denominator) / p
    }
    
    # Check for convergence
    if (max(abs(beta_new - beta)) < tol) break
    beta <- beta_new
    iter <- iter + 1
  }
  
  end_time <- Sys.time()  # end timing
  return(list(beta = beta, time = end_time - start_time, iter = iter))
}