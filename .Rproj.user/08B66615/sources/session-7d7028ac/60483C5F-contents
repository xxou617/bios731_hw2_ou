#####################################################################################
# Julia Wrobel
# January 2025
#
# This file produces implements an EM algorithm for a two-part Gaussian MM
#####################################################################################

library(tidyverse)

data("faithful")

hist(faithful$waiting)




# things to define or the function
max_iterations = 100
tol_criteria = Inf
tol = .0001

y = faithful$waiting
n = length(y)
iter = 1

## initialize parameter values- what might be more informative initialization values?
mu1 = 50
mu2 =  80
sigma1 = 1
sigma2 = 1
lambda = 0.5

# define vectors to store elements of interest
observed_ll = rep(NA, length = max_iterations)

while(iter < max_iterations  & tol_criteria > tol){

  ###############################################################
  ## E-step
  ###############################################################

  # normal density for first mixture
  f1 = dnorm(y, mean = mu1, sd = sqrt(sigma1), log = FALSE)
  f2 = dnorm(y, mean = mu2, sd = sqrt(sigma2), log = FALSE)

  # compute current value of Q function and pi
  # don't actually need Q function current estimate for M-step, by the way
  pi =  lambda * f1 / (lambda * f1 + (1-lambda) * f2)

  ###############################################################
  ## M-step
  ###############################################################

  mu1 = sum(pi * y)/sum(pi)
  mu2 = sum((1-pi)*y)/sum(1-pi)

  sigma1 = sum(pi * (y - mu1)^2)/sum(pi)
  sigma2 = sum((1-pi)*(y - mu2)^2)/sum(1-pi)

  lambda = sum(pi)/n
  ###############################################################

  ## set up elements to define observed data likelihood
  f1 = dnorm(y, mean = mu1, sd = sqrt(sigma1))
  f2 = dnorm(y, mean = mu2, sd = sqrt(sigma2))

  ## define log likelihood at current iteration
  observed_ll[iter] = sum(log(lambda * f1 + (1-lambda) * f2))

  if(iter > 1){
    tol_criteria = observed_ll[iter] - observed_ll[iter-1]
  }
  iter = iter + 1
  message(paste0("iteration: ", iter, "; ll: ", round(tol_criteria, 4)))
}


### return parameters of interest
# current estimates of z
# estimates of theta
# estimates of Q at each iteration
# estimates of l(theta|y) at each iteration
# estimates of

tibble(iteration = 1:max_iterations,
       observed_ll = observed_ll) %>%
  filter(!is.na(observed_ll)) %>%
  ggplot(aes(iteration, observed_ll)) +
  geom_line()




mu1
mu2
sigma1
sigma2
lambda
